{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "ths = pd.read_csv('THS.csv')\n",
    "cols = [\"ID\",\"Location\",\"Region\",\"Denomination\",\"Date1\",\"Date2\",\"Number\",\"Notes\",\"Bibliography\"]\n",
    "ths.columns = cols\n",
    "ths.index = ths['ID']\n",
    "\n",
    "# function to convert denominations to the standard nummi notation\n",
    "def convert_denomination(df):\n",
    "\tdi = {'K':'20 nummi', 'IS':'16 nummi', 'M':'40 nummi', 'B':'2 nummi', 'A':'1 nummus', 'H':'8 nummi', 'I':'10 nummi', 'E':'5 nummi', 'D':'4 nummi'}\n",
    "\tdf = df.replace({'Denomination':di})\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build the coin_finds dataframe\n",
    "def setting_coin_finds(ths):\n",
    "    cols_finds = ['hoard_id', 'name', 'startDate', 'endDate', 'type_find', 'hoard?', 'excavation?', 'single?', 'num_coins', 'num_known_coins', 'year_found',\n",
    "        'year_end_found', 'comments', 'bibliography', 'lat', 'long', 'certainty', 'owner', 'created', 'imported']\n",
    "    coin_finds = pd.DataFrame(index=ths.index, columns=cols_finds)\n",
    "    \n",
    "    ids = pd.Series(ths.index).apply(str)   \n",
    "    coin_finds['hoard_id'] = 'THS-' + (ids.values)\n",
    "    coin_finds['name'] = ths['Location'] + ', ' + ths['Region'] + '(' + coin_finds['hoard_id'] + ')'\n",
    "    coin_finds['place_small'] = ths['Location']\n",
    "    coin_finds['place_large'] = ths['Region']\n",
    "    coin_finds['startDate'] = ths['Date1']\n",
    "    coin_finds['endDate'] = ths['Date2']\n",
    "    coin_finds['hoard?'] = 0\n",
    "    coin_finds['excavation?'] = 0\n",
    "    coin_finds['single?'] = 1\n",
    "    coin_finds['type_find'] = 'single find'\n",
    "    coin_finds['num_coins'] = ths['Number']\n",
    "    coin_finds['num_known_coins'] = ths['Number']\n",
    "    coin_finds['certainty'] = 'highest' #meaning certain\n",
    "    coin_finds['owner'] = 'AG THS'\n",
    "    coin_finds['created'] = pd.Timestamp.now()\n",
    "    coin_finds['imported'] = pd.Timestamp.now()\n",
    "    coin_finds['comments'] = ths['Notes']\n",
    "    coin_finds['bibliography'] = ths['Bibliography']\n",
    "    \n",
    "    # sort out certainty\n",
    "    uncertain = ['Yapi Credi', 'Crete', 'Banat', 'Palestine', 'Moesia Secunda', 'Bucovina', 'Lazica', 'Dobrudja', 'Oltenia', 'Transylvania']\n",
    "    very_uncertain = ['Mesopotamia', 'Anatolia']\n",
    "\n",
    "    # marking very_uncertain places as 3, uncertain places as 2\n",
    "    coin_finds.loc[coin_finds['place_small'].isin(very_uncertain), 'certainty'] = 'lowest'\n",
    "    coin_finds.loc[coin_finds['place_small'].isin(uncertain), 'certainty'] = 'lower'\n",
    "    \n",
    "    return coin_finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to set the coin_groups dataframe\n",
    "def setting_coin_groups(ths):\n",
    "    cols = ['hoard_id', 'coin_group_id', 'start_year', 'end_year', 'revised_start', 'revised_end', 'ruler',\n",
    "        'dynasty', 'denomination', 'num_coins', 'mint', 'imported', 'created', 'updated']\n",
    "    coin_groups = pd.DataFrame(index=ths.index, columns=cols)\n",
    "\n",
    "    ids = pd.Series(ths.index).apply(str)   \n",
    "    coin_groups['hoard_id'] = 'THS-' + (ids.values)\n",
    "    coin_groups['coin_group_id'] = coin_groups['hoard_id'] + '-1' # since these are all single finds\n",
    "    coin_groups['start_year'] = ths['Date1']\n",
    "    coin_groups['end_year'] = ths['Date2']\n",
    "    coin_groups['revised_start'] = coin_groups['start_year']\n",
    "    coin_groups['revised_end'] = coin_groups['end_year']\n",
    "    coin_groups['ruler'] = 'placeholder'\n",
    "    coin_groups['dynasty'] = 'Eastern Roman Empire' # filling in dynasty\n",
    "    coin_groups['denomination'] = ths['Denomination']\n",
    "    coin_groups['num_coins'] = ths['Number']\n",
    "    coin_groups['mint'] = 'Thessaloniki'\n",
    "    coin_groups['imported'] = pd.Timestamp.now()\t# this and the next two lines are identical because importing should be a one-off thing.\n",
    "    coin_groups['created'] = pd.Timestamp.now()\n",
    "    coin_groups['updated'] = pd.Timestamp.now()\n",
    "\n",
    "    return coin_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(len(coordinates_df.index)):\\n    coin_finds.loc[coin_finds.place_small == coordinates_df.index[i], 'lat'] = coordinates_df['Lat'].iloc[i]\\n    coin_finds.loc[coin_finds.place_small == coordinates_df.index[i], 'long'] = coordinates_df['Lng'].iloc[i]\\n\\ncoin_finds.head()\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this cell was used for getting coordinates from Google; now obsolete since getting coordinates from Andrei's file.\n",
    "'''\n",
    "import requests, json\n",
    "\n",
    "def get_coordinates(place_name):\n",
    "    gKey = 'AIzaSyAEhSDZteGTpcXp9dYNUhB1AhHuF9r1kFo'\n",
    "    geoURL = 'https://maps.googleapis.com/maps/api/geocode/json?address=' + place_name + '&key=' + gKey\n",
    "\n",
    "    r = requests.get(geoURL)\n",
    "    temp = json.loads(r.text)\n",
    "    if temp['results'] == []:\n",
    "        return False\n",
    "    else:\n",
    "        lat = temp['results'][0]['geometry']['location']['lat']\n",
    "        lng = temp['results'][0]['geometry']['location']['lng']\n",
    "        return([lat, lng])\n",
    "\n",
    "\n",
    "try:\n",
    "    coordinates_df = pd.read_csv('coordinates.csv')\n",
    "\n",
    "except:\n",
    "    temp = coin_finds['place_small'][:]\n",
    "    temp_set = set(temp)\n",
    "    #len(temp_set)\n",
    "    cols = ['Lat', 'Lng']\n",
    "    coordinates_df = pd.DataFrame(list(temp_set), columns=['Name'])\n",
    "    coordinates_df['Lat'] = np.nan\n",
    "    coordinates_df['Lng'] = np.nan\n",
    "\n",
    "    coordinates = coordinates_df['Name'].apply(get_coordinates)\n",
    "    \n",
    "    lats = []\n",
    "    lngs = []\n",
    "    for i in coordinates:\n",
    "        if i != False:\n",
    "            lats.append(i[0])\n",
    "            lngs.append(i[1])\n",
    "        else:\n",
    "            lats.append(False)\n",
    "            lngs.append(False)\n",
    "\n",
    "    coordinates_df['Lat'] = lats\n",
    "    coordinates_df['Lng'] = lngs\n",
    "    coordinates_df = coordinates_df.set_index('Name')\n",
    "\n",
    "    coordinates_df.to_csv('coordinates.csv')\n",
    "'''\n",
    "\n",
    "# uses df to populate coin_finds\n",
    "'''\n",
    "for i in range(len(coordinates_df.index)):\n",
    "    coin_finds.loc[coin_finds.place_small == coordinates_df.index[i], 'lat'] = coordinates_df['Lat'].iloc[i]\n",
    "    coin_finds.loc[coin_finds.place_small == coordinates_df.index[i], 'long'] = coordinates_df['Lng'].iloc[i]\n",
    "\n",
    "coin_finds.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex = r'([0-9]{4})|([0-9]{4}-[0-9]{4})'\n",
    "\n",
    "# gets all the required information from the bibliography\n",
    "def get_info_from_bib(text_line):\n",
    "    space_loc = text_line.find(\" \")\n",
    "    author = text_line[:space_loc]\n",
    "    equal_loc = text_line.find(\" =\")\n",
    "    \n",
    "    temp = re.search(regex, text_line)\n",
    "    years = temp.group() # covers the years in XXXX or XXXX-YYYY format\n",
    "    \n",
    "    year_start = temp.start()\n",
    "    long_author = text_line[:int(year_start)-1]\n",
    "    \n",
    "    reference = text_line[equal_loc+3:]\n",
    "    \n",
    "    return [author, years, long_author, reference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gets all the required information from a bibliographic entry in the database\n",
    "def get_info_from_db(text_line):\n",
    "    comma_loc = text_line.find(\",\")\n",
    "    author = text_line[:comma_loc]\n",
    "    \n",
    "    temp = re.search(regex, text_line)\n",
    "    try:\n",
    "        years = temp.group() # covers the years in XXXX or XXXX-YYYY format\n",
    "    except:\n",
    "        #print(text_line)\n",
    "        years = ''\n",
    "\n",
    "    return [author, years]\n",
    "\n",
    "# tested and this works\n",
    "#test_list = list(coin_finds['bibliography'].head(50))\n",
    "#for i in test_list:\n",
    "#    print(get_info_from_db(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reading & fixing bibliographic entries\n",
    "def get_bibliography():\n",
    "    # reads bibliographic entries\n",
    "    with open('ths-bib.txt') as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    content = [x.strip() for x in content]\n",
    "    biblio = []\n",
    "    for i in content[:]:\n",
    "        #print(i)\n",
    "        biblio.append(get_info_from_bib(i))\n",
    "   \n",
    "    bibliography = pd.DataFrame(biblio, columns=['Author', 'Year', 'Long_Author', 'Reference'])\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ț', 't')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ţ', 't')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ä', 'a')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('é', 'e')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ö', 'o')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ș', 's')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ș', 's')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ă', 'a')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ç', 'c')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('Ç', 'C')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('î', 'i')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('í', 'i')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ć', 'c')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('š', 's')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('Š', 'S')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('č', 'c')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ğ', 'g')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('Ü', 'U')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ł', 'l')\n",
    "    bibliography['Author'] = bibliography['Author'].str.replace('ı', 'i')\n",
    "    return bibliography\n",
    "\n",
    "def get_full_reference(author_name, year, bibliography):\n",
    "    author_works = bibliography[bibliography['Author'] == author_name]\n",
    "    if author_name == 'MINAC 2004': return 'Partial reference: '\n",
    "    if author_name[0:4] == 'MNIR': return 'Partial reference: '\n",
    "    if author_name[0:4] == 'Info': return 'Personal reference: '\n",
    "    \n",
    "    author_year = author_works[author_works['Year'] == year]\n",
    "    # missing references:\n",
    "    if (author_name == 'Custurea') and (year == '1995'): return 'Missing reference?: '\n",
    "    if (author_name == 'Vertan') and (year == '1997'): return 'Missing reference?: '\n",
    "    if (author_name[0:5] == 'Waage') and (year == '1952'): return 'Missing reference?: '\n",
    "    if (author_name[0:6] == 'Zeliha'): return 'Missing reference?: '\n",
    "    if (author_name[0:6] == 'Cherub'): return 'Missing reference?: '\n",
    "    if (author_name[0:10] == 'Dekoulakou'): return 'Missing reference?: '\n",
    "    \n",
    "    # corrupted references - MUST verify these results, some of their bibliographies are corrupted or uncertain based on the existing list I received:\n",
    "    if (author_name == 'Poenaru, Ocheseanu, BSNR 86-87, 88, no. 5'): return 'Corrupted reference?: '\n",
    "    if (author_name == 'Poenaru') and (year == ''): return 'Corrupted reference?: '\n",
    "    if (author_name[0:8] == 'Nudelman'): return 'A. A. Nudel’man, Topografiia kladov i nakhodok edinichnykh monet, Kishinew.'\n",
    "    if (author_name[0:8] == 'Mussorov'): return 'A. I. Mussurov & L. V. Nosova, Nakhodki vizantiiskikh monet V-VI vv. nа Nizhnem Dnestre, Stratum+ 6, p. 304-306.'\n",
    "    if (author_name[0:6] == 'Teodor'): return 'D. G. Teodor, Teritoriul est-carpatic în veacurile V-XI e.n.: contribuții arheologice și istorice la problema formării poporului român, Iaşi.'\n",
    "    if (author_name[0:6] == 'Velter'): return 'A.-M. Velter, Transilvania în secolele V-XII. Interpretări istorico-politice și economice pe baza descoperirilor monetare din bazinul Carpatic, secolele V-XII, Bucharest.'\n",
    "    \n",
    "    if (author_name[0:9] == 'Stoliarik'): return 'E. Stolyarik, Essays on monetary circulation in the North-Western Black Sea region in the Late Roman and Early Byzantine periods: late 3rd century – early 13th century A.D., Odessa.'\n",
    "    if (author_name[0:7] == 'Somogyi'): return 'P. Somogyi, Byzantinische Fundmünzen der Awarenzeit. Einem Bestandsaufnahme, 1998-2007, Acta Archaeologica Carpathica 42-43, p. 231-298.'\n",
    "    if (author_name[0:12] == 'Abramishvili') and (year == ''): return 'Nokalakevis arkeologiuri ekspeditsiis mier bolo ts’legshi gamovlenili numizmat’ik’uri masla, in P. Zakaraia (ed.), Nokalakevi-Arkeopolisi: III. Arkeologiuri gatchrebi 1983-1989, Tbilisi, p. 270-272.'\n",
    "    if (author_name[0:6] == 'Mirnik') and (year == '1998' or year == ''): return 'I. Mirnik & A. Šemrov, Byzantine coins in the Zagreb Archaeological Museum numismatic collection. Anastasius I (A.D. 497-518) - Anastasius II (A.D. 713–715), Vjesnik Arheološkog Muzeja u Zagrebu 30-31, p. 129-258.'\n",
    "    if (author_name[0:11] == 'Georganteli'): return \"E. Georganteli, L’espace rural dans la province de Rhodope; le témoignage de la numismatique, in J. Lefort, C. Morrisson & J.-P. Sodini (eds.), Les villages dans l'Empire byzantin (IVe-XVe siècle), Paris, p. 307-318.\"\n",
    "\n",
    "    if (author_name[0:10] == 'Mihailescu'): return 'V. Mihăilescu-Bîrliba & C. Mihai, Descoperiri monetare la Târgu Frumos, jud. Iaşi, Arheologia Moldovei 19, p. 253-259.'\n",
    "    if (author_name[0:6] == 'Winter'): return 'Die byzantinischen Fundmünzen aus dem österreichischen Bereich der Avaria, in F. Daim (ed.), Die Awaren am Rand der byzantinischen Welt: Studien zu Diplomatie, Handel und Technologietransfer im Frühmittelalter, Innsbruck, 45-66.'\n",
    "    if (author_name[0:13] == 'Sagalassos IV'): return 'S. Scheers, Coins found in 1994 and 1995, in M. Waelkens & J. Poblome (eds.), Sagalassos IV. Report on the survey and excavation campaigns of 1994 and 1995, Leuven, p. 315-350.'\n",
    "    if (author_name[0:12] == 'Sagalassos V'): return 'S. Scheers, Coins found in 1996 and 1997, in M. Waelkens & L. Loots (eds.), Sagalassos V. Report on the survey and excavation campaigns of 1996–1997, Leuven, 509-549.'\n",
    "    if (author_name[0:7] == 'Ireland'): return 'S. Ireland, Greek, Roman and Byzantine coins in the museum at Amasya, London.'\n",
    "    \n",
    "    if (author_name[0:7] == 'Goricke'): return 'H. Göricke-Lukić, Justinijanov novac iz Slavonije i Baranje, in N. Cambi & E. Marin (eds.), Radovi XIII. Meðunarodnog kongresa za starokrščansku arheologija. Split-Poreč '\n",
    "    if (author_name[0:7] == 'Vetters'): return 'S. Karwiese, Ephesos 1980: Liste der Fundmünzen, in H. Vetters (ed.), Ephesos. Vorläufiger Grabungsbericht 1980, Vienna, p. 154-160.'\n",
    "    if (author_name[0:4] == 'Okcu'): return 'R. Okçu (ed.), The Archaeological Museum of Bursa: coin exhibition catalogue, Bursa.'\n",
    "    if (author_name[0:4] == 'Bell'): return 'Missing reference: '\n",
    "    if (author_name[0:7] == 'Tsourti'): return 'E. Tsourti, Antikyra Boiotias. Nomismatiki marturia, in L. Kypraiou (ed.), Thorakion: aphieroma ste mneme tou Paulou Lazaride, Athens, p. 123-128.'\n",
    "    if (author_name[0:8] == 'Boshkova'): return 'B. Bozhkova, Monetni nakhodki ot arkheologicheski kompleks (IV-VII v.) “Iuzhen Park – Lozenets”, Sofiia, Numizmatika, sfragistika i epigrafica 1, p. 73-86.'\n",
    "    if (author_name[0:3] == 'Kos'): return 'P. Kos, The monetary circulation in the Southeastern Alpine region ca 300 B.C. - A.D. 1000, Situla 24, p. 1-254.'\n",
    "    \n",
    "    if (author_name[0:6] == 'Fisher'):\n",
    "        if (year == '1971'): return 'C. K. Williams II & J. Fisher, Corinth, 1970: Forum area, Hesperia 40, no. 1, p. 1-51.'\n",
    "        if (year == '1975'): return 'C. K. Williams II & J. Fisher, Corinth, 1974: Forum Southwest, Hesperia 44, no. 1, p. 1-50.'\n",
    "        if (year == '1976'): return 'C. K. Williams II & J. Fisher, Corinth, 1975: Forum Southwest, Hesperia 45, no. 2, p. 99-162.'\n",
    "    if (author_name[0:6] == 'Zervos'): \n",
    "        if year == '1986': return 'C. K. Williams II & O. H. Zervos, Corinth, 1985: east of the theater, Hesperia 55, no. 2, p. 129-175. '\n",
    "        if year == '1991': return 'C. K. Williams II & O. H. Zervos, Corinth, 1985: east of the theater, Hesperia 55, no. 2, p. 129-175. '\n",
    "    \n",
    "    \n",
    "    # the reference below is missing a year in the database\n",
    "    if (author_name == 'Oberlander') and (year == ''): return 'E. Oberländer-Târnoveanu & E.-M. Constantinescu, Monede romane târzii şi bizantine din colecţia Muzeului Judeţean Buzău, Mousaios 4, p. 311-341.'\n",
    "    if (author_name == 'Butnariu'): return 'V. M. Butnariu, Răspîndirea monedelor bizantine din secolele VI-VII în teritoriile carpato-dunărene, Buletinul Societății Numismatice Române 131-133, p. 199-235.'\n",
    "    if (author_name[0:6] == 'Arslan'): return 'E. Arslan (ed.), Repertorio dei ritrovamenti di moneta Altomedievale in Italia (489-1002). http://www.ermannoarslan.it/Repertorio/index.php (last update, 30 August, 2016).'\n",
    "    \n",
    "    # this has a discrepancy between year in dataset and year in bibliography\n",
    "    if (author_name[0:7] == 'Lazarov'): return 'L. Lazarov, Moneti ot 16 numii na Iustinian I, secheni v Tesalonika i otkriti v Bulgariia, Numizmatika 25, no. 1-2, p. 16-22.'\n",
    "\n",
    "    space_loc = author_name.find(\" \")\n",
    "    if space_loc > -1:\n",
    "        #print(author_name, end=\", \")\n",
    "        author_name = author_name[:space_loc]\n",
    "        author_works = bibliography[bibliography['Author'] == author_name]\n",
    "        author_year = author_works[author_works['Year'] == year]\n",
    "        #print(author_name, author_year)\n",
    "    \n",
    "    try:\n",
    "        reference = list(author_year['Reference'])[0]\n",
    "        return reference\n",
    "    except:\n",
    "        print('Error in get_full_reference: ', end=' ')\n",
    "        print(author_name + \"-\" + year)\n",
    "\n",
    "#get_full_reference('Mihaylov', '2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ruler(start, end):\n",
    "    if start >= 518 and end <= 527: return 'Justin I'\n",
    "    if start >= 527 and end <= 565: return 'Justinian I'\n",
    "    if start >= 565 and end <= 578: return 'Justin II'\n",
    "    if start >= 578 and end <= 582: return 'Tiberius II Constantine'\n",
    "    if start >= 582 and end <= 602: return 'Maurice'\n",
    "    if start >= 602 and end <= 608: return 'Phokas'\n",
    "    return 'Heraklios'\n",
    "\n",
    "#dealing with coordinates\n",
    "def simplify(temp_str):\n",
    "    temp_str = temp_str.replace('ț', 't')\n",
    "    temp_str = temp_str.replace('ţ', 't')\n",
    "    temp_str = temp_str.replace('ä', 'a')\n",
    "    temp_str = temp_str.replace('é', 'e')\n",
    "    temp_str = temp_str.replace('ö', 'o')\n",
    "    temp_str = temp_str.replace('ü', 'u')\n",
    "    temp_str = temp_str.replace('ë', 'e')\n",
    "    temp_str = temp_str.replace('ș', 's')\n",
    "    temp_str = temp_str.replace('ș', 's')\n",
    "    temp_str = temp_str.replace('ă', 'a')\n",
    "    temp_str = temp_str.replace('â', 'a')\n",
    "    temp_str = temp_str.replace('ç', 'c')\n",
    "    temp_str = temp_str.replace('Ç', 'C')\n",
    "    temp_str = temp_str.replace('î', 'i')\n",
    "    temp_str = temp_str.replace('í', 'i')\n",
    "    temp_str = temp_str.replace('ć', 'c')\n",
    "    temp_str = temp_str.replace('š', 's')\n",
    "    temp_str = temp_str.replace('Š', 'S')\n",
    "    temp_str = temp_str.replace('Ș', 'S')\n",
    "    temp_str = temp_str.replace('č', 'c')\n",
    "    temp_str = temp_str.replace('ğ', 'g')\n",
    "    temp_str = temp_str.replace('Ü', 'U')\n",
    "    temp_str = temp_str.replace('ł', 'l')\n",
    "    temp_str = temp_str.replace('ı', 'i')\n",
    "    space = temp_str.find(' ')\n",
    "    if space > -1:\n",
    "        temp_str = temp_str[:space]\n",
    "    return temp_str\n",
    "\n",
    "# fixing exception w/ coordinates\n",
    "def fix_locations(ths):    \n",
    "    ths.loc[ths['Location'] == 'Smirna', 'Location'] = 'Smyrna'\n",
    "    #ths.loc[ths['Location'] == 'SantAgata Feltria', 'Location'] = 'Smyrna'\n",
    "    ths.loc[ths['Location'] == 'Bichvinta', 'Location'] = 'Bich’vinta'\n",
    "    ths.loc[ths['Location'] == 'Ephesus', 'Location'] = 'Efes Ephesus'\n",
    "    ths.loc[ths['Location'] == 'Hammat Gader', 'Location'] = 'Hamat Gader'\n",
    "    ths.loc[ths['Location'] == 'Patalenitsa', 'Location'] = 'Patelenitsa'\n",
    "    ths.loc[ths['Location'] == 'Halmyris', 'Location'] = 'Murighiol (Halmyris)'\n",
    "    ths.loc[ths['Location'] == 'Heracleion', 'Location'] = 'Herakleion'\n",
    "    ths.loc[ths['Location'] == 'Melitene', 'Location'] = 'Malatya (Melitene)'\n",
    "    ths.loc[ths['Location'] == 'Mt Nebo', 'Location'] = 'Mount Nebo'\n",
    "    ths.loc[ths['Location'] == 'Dionysopolis', 'Location'] = 'Balchik (Dionyssopolis)'\n",
    "    ths.loc[ths['Location'] == 'Salamis', 'Location'] = 'Salamis-Constantia'\n",
    "    ths.loc[ths['Location'] == 'Szegvar', 'Location'] = 'Segvar'\n",
    "    ths.loc[ths['Location'] == 'Barbalissus', 'Location'] = 'Balis (Barbalissus)'\n",
    "    ths.loc[ths['Location'] == 'Schutzen am Gebirge', 'Location'] = 'Shutzen am Gebirge'\n",
    "    ths.loc[ths['Location'] == 'Dunareni-Bratca', 'Location'] = 'Dunareni-Bratca'\n",
    "    ths.loc[ths['Location'] == 'Sacidava', 'Location'] = 'Sacidava'\n",
    "    #ths.loc[ths['Location'] == 'Ostrov', 'Location'] = ''\n",
    "    #ths.loc[ths['Location'] == 'Yapi Credi', 'Location'] = ''\n",
    "    #ths.loc[ths['Location'] == 'Sofia-Lozenets', 'Location'] = ''\n",
    "    #ths.loc[ths['Location'] == 'Troesmis-Iglita', 'Location'] = ''\n",
    "    ths.loc[ths['Location'] == 'Moesia II', 'Location'] = 'Moesia Secunda'\n",
    "\n",
    "    return ths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_bibliography(coin_finds):\n",
    "    bibliography = get_bibliography()\n",
    "    test_list = list(coin_finds['bibliography'])\n",
    "    full_references = []\n",
    "    for i in test_list:\n",
    "        author_and_date = get_info_from_db(i)\n",
    "        ref = get_full_reference(author_and_date[0], author_and_date[1], bibliography)\n",
    "        full_references.append(ref)\n",
    "    print(len(full_references), end=' ')\n",
    "    print('References; should be 1228.')\n",
    "    return full_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_andrei_coordinates(place, andrei):\n",
    "    place = simplify(place)\n",
    "    try:\n",
    "        lat = andrei.loc[place]['lat']\n",
    "        lng = andrei.loc[place]['lng']\n",
    "        #if type(lat) != str:\n",
    "        #    lat = lat.iloc[0]\n",
    "        #    lng = lng.iloc[0]\n",
    "        return [lat, lng]\n",
    "    except:\n",
    "        print('Error: ' + place + ' not in index.')\n",
    "        return 1\n",
    "\n",
    "def fix_coordinates(ths, andrei):\n",
    "    cnt = 0\n",
    "    error_list = []\n",
    "    lat = []\n",
    "    lng = []\n",
    "    for i in range(len(list(ths['Location']))):\n",
    "        counter = get_andrei_coordinates(ths['Location'].iloc[i], andrei)\n",
    "        if type(counter) == int:\n",
    "            cnt += 1\n",
    "            error_list.append(ths['Location'].iloc[i])\n",
    "        else:\n",
    "            lat.append(counter[0])\n",
    "            lng.append(counter[1])       \n",
    "\n",
    "    set_errors = set(error_list)\n",
    "    if len(set_errors) == 0:\n",
    "        print('No errors with locations')\n",
    "    else:\n",
    "        print(set_errors)\n",
    "        print(len(set_errors))\n",
    "    return lat,lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nths = pd.read_csv(\\'THS.csv\\')\\ncols = [\"ID\",\"Location\",\"Region\",\"Denomination\",\"Date1\",\"Date2\",\"Number\",\"Notes\",\"Bibliography\"]\\nths.columns = cols\\nths.index = ths[\\'ID\\']\\nths = convert_denomination(ths)\\nths = fix_locations(ths)\\n\\n\\nandrei = pd.read_csv(\\'andreicoordinates.csv\\')\\nandrei[\\'Name\\'] = andrei[\\'Name\\'].apply(simplify)\\nandrei = andrei.set_index(\\'Name\\')\\n\\n\\nfix_coordinates(ths[1000:1200], andrei)\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete this cell after testing:\n",
    "'''\n",
    "ths = pd.read_csv('THS.csv')\n",
    "cols = [\"ID\",\"Location\",\"Region\",\"Denomination\",\"Date1\",\"Date2\",\"Number\",\"Notes\",\"Bibliography\"]\n",
    "ths.columns = cols\n",
    "ths.index = ths['ID']\n",
    "ths = convert_denomination(ths)\n",
    "ths = fix_locations(ths)\n",
    "\n",
    "\n",
    "andrei = pd.read_csv('andreicoordinates.csv')\n",
    "andrei['Name'] = andrei['Name'].apply(simplify)\n",
    "andrei = andrei.set_index('Name')\n",
    "\n",
    "\n",
    "fix_coordinates(ths[1000:1200], andrei)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228 References; should be 1228.\n"
     ]
    }
   ],
   "source": [
    "# main part begins here\n",
    "ths = convert_denomination(ths)\n",
    "ths = fix_locations(ths)\n",
    "\n",
    "coin_finds = setting_coin_finds(ths)\n",
    "coin_groups = setting_coin_groups(ths)\n",
    "\n",
    "coin_finds['full_bibliography'] = get_full_bibliography(coin_finds) # establishing bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting ruler for all entries\n",
    "start_years = list(coin_groups['start_year'])\n",
    "end_years = list(coin_groups['end_year'])\n",
    "rulers = []\n",
    "for i in range(len(start_years)):\n",
    "    ruler = get_ruler(start_years[i], end_years[i])\n",
    "    rulers.append(ruler)\n",
    "coin_groups['ruler'] = rulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors with locations\n"
     ]
    }
   ],
   "source": [
    "andrei = pd.read_csv('andreicoordinates.csv')\n",
    "andrei['Name'] = andrei['Name'].apply(simplify)\n",
    "andrei = andrei.set_index('Name')\n",
    "\n",
    "lat, lng = fix_coordinates(ths,andrei)\n",
    "coin_finds['lat'] = lat\n",
    "coin_finds['long'] = lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "0             NaN\n",
       "1       44.083330\n",
       "2       44.921000\n",
       "3       44.683333\n",
       "4       44.683333\n",
       "5       44.683333\n",
       "6       44.683333\n",
       "7       44.683333\n",
       "8       43.800000\n",
       "9       43.800000\n",
       "10      27.988644\n",
       "11      27.988644\n",
       "12      27.988644\n",
       "13      43.966667\n",
       "14      43.966667\n",
       "15      44.155000\n",
       "16      43.800000\n",
       "17      43.800000\n",
       "18      43.800000\n",
       "19      45.266670\n",
       "20      45.266670\n",
       "21      45.266670\n",
       "22      45.266670\n",
       "23      45.266670\n",
       "24      45.266670\n",
       "25      45.266670\n",
       "26      45.266670\n",
       "27      45.266670\n",
       "28      45.266670\n",
       "29      45.266670\n",
       "          ...    \n",
       "1198    28.534448\n",
       "1199    28.534448\n",
       "1200    34.664200\n",
       "1201    34.664200\n",
       "1202    34.664200\n",
       "1203    39.875000\n",
       "1204    40.818333\n",
       "1205    40.818333\n",
       "1206    39.266667\n",
       "1207    40.818333\n",
       "1208    41.013056\n",
       "1209    37.616667\n",
       "1210    37.616667\n",
       "1211    41.010833\n",
       "1212    20.921667\n",
       "1213    23.037837\n",
       "1214    23.037837\n",
       "1215    23.037837\n",
       "1216    23.037837\n",
       "1217    23.037837\n",
       "1218    23.037837\n",
       "1219    23.037837\n",
       "1220    23.037837\n",
       "1221    23.037837\n",
       "1222    23.037837\n",
       "1223    15.486914\n",
       "1224    42.033333\n",
       "1225    42.033333\n",
       "1226    42.033333\n",
       "1227    42.033333\n",
       "Name: long, Length: 1228, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = []\n",
    "for i in range(len(lng)):\n",
    "    try:\n",
    "        if ' ' in lng[i]: ttt.append(i)\n",
    "    except:\n",
    "        ttt.append(i)\n",
    "\n",
    "coin_finds.loc[ttt]['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_finds.to_csv('ths_finds')\n",
    "coin_groups.to_csv('ths_coins')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coin_groups[(coin_groups['revised_start'] >= 527) & (coin_groups['revised_end'] <= 541)]['num_coins'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'na'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-9de9b2c13854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcoin_finds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'long'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#coin_finds.describe()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'na'"
     ]
    }
   ],
   "source": [
    "coin_finds['long'].na()\n",
    "#coin_finds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_finds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
